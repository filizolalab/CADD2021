{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 01_The_Basic_Tools_of_the_Deep_Life_Sciences.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/filizolalab/CADD2021/blob/main/solubility.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "socSJe925zFv"
      },
      "source": [
        "#  The Basic Tools of the Deep Life Sciences\n",
        "Welcome to DeepChem's introductory tutorial for the deep life sciences. This series of notebooks is a step-by-step guide for you to get to know the new tools and techniques needed to do deep learning for the life sciences. We'll start from the basics, assuming that you're new to machine learning and the life sciences, and build up a repertoire of tools and techniques that you can use to do meaningful work in the life sciences.\n",
        "\n",
        "**Scope:** This tutorial will encompass both the machine learning and data handling needed to build systems for the deep life sciences.\n",
        "\n",
        "## Colab\n",
        "\n",
        "This tutorial and the rest in the sequences are designed to be done in Google colab. If you'd like to open this notebook in colab, you can use the following link.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deepchem/deepchem/blob/master/examples/tutorials/The_Basic_Tools_of_the_Deep_Life_Sciences.ipynb)\n",
        "\n",
        "\n",
        "## Why do the DeepChem Tutorial?\n",
        "\n",
        "**1) Career Advancement:** Applying AI in the life sciences is a booming\n",
        "industry at present. There are a host of newly funded startups and initiatives\n",
        "at large pharmaceutical and biotech companies centered around AI. Learning and\n",
        "mastering DeepChem will bring you to the forefront of this field and will\n",
        "prepare you to enter a career in this field.\n",
        "\n",
        "**2) Humanitarian Considerations:** Disease is the oldest cause of human\n",
        "suffering. From the dawn of human civilization, humans have suffered from pathogens,\n",
        "cancers, and neurological conditions. One of the greatest achievements of\n",
        "the last few centuries has been the development of effective treatments for\n",
        "many diseases. By mastering the skills in this tutorial, you will be able to\n",
        "stand on the shoulders of the giants of the past to help develop new\n",
        "medicine.\n",
        "\n",
        "**3) Lowering the Cost of Medicine:** The art of developing new medicine is\n",
        "currently an elite skill that can only be practiced by a small core of expert\n",
        "practitioners. By enabling the growth of open source tools for drug discovery,\n",
        "you can help democratize these skills and open up drug discovery to more\n",
        "competition. Increased competition can help drive down the cost of medicine.\n",
        "\n",
        "## Getting Extra Credit\n",
        "If you're excited about DeepChem and want to get more involved, there are some things that you can do right now:\n",
        "\n",
        "* Star DeepChem on GitHub! - https://github.com/deepchem/deepchem\n",
        "* Join the DeepChem forums and introduce yourself! - https://forum.deepchem.io\n",
        "* Say hi on the DeepChem gitter - https://gitter.im/deepchem/Lobby\n",
        "* Make a YouTube video teaching the contents of this notebook.\n",
        "\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "This tutorial sequence will assume some basic familiarity with the Python data science ecosystem. We will assume that you have familiarity with libraries such as Numpy, Pandas, and TensorFlow. We'll provide some brief refreshers on basics through the tutorial so don't worry if you're not an expert.\n",
        "\n",
        "## Setup\n",
        "\n",
        "The first step is to get DeepChem up and running. We recommend using Google Colab to work through this tutorial series. You'll also need to run the following commands to get DeepChem installed on your colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMWAv-Z46nCc",
        "outputId": "f370d2c1-9101-4a0a-9771-d83944481ee7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install --pre deepchem"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepchem\n",
            "  Downloading deepchem-2.6.0.dev20211117164926-py3-none-any.whl (609 kB)\n",
            "\u001b[?25l\r\u001b[K     |▌                               | 10 kB 26.6 MB/s eta 0:00:01\r\u001b[K     |█                               | 20 kB 29.9 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 30 kB 32.5 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 40 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 51 kB 25.2 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 61 kB 16.6 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 71 kB 16.7 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 81 kB 17.0 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 92 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 102 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████                          | 112 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 122 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████                         | 133 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 143 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████████                        | 153 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 163 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 174 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 184 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 194 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 204 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 215 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 225 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 235 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 245 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 256 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 266 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 276 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 286 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 296 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 307 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 317 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 327 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 337 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 348 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 358 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 368 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 378 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 389 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 399 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 409 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 419 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 430 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 440 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 450 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 460 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 471 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 481 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 491 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 501 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 512 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 522 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 532 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 542 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 552 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 563 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 573 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 583 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 593 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 604 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 609 kB 19.4 MB/s \n",
            "\u001b[?25hCollecting rdkit-pypi\n",
            "  Downloading rdkit_pypi-2021.9.2.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.6 MB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.19.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from deepchem) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->deepchem) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->deepchem) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->deepchem) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->deepchem) (3.0.0)\n",
            "Installing collected packages: rdkit-pypi, deepchem\n",
            "Successfully installed deepchem-2.6.0.dev20211117164926 rdkit-pypi-2021.9.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jk47QTZ95zF-"
      },
      "source": [
        "You can of course run this tutorial locally if you prefer. In this case, don't run the above cell since it will download and install Anaconda on your local machine. In either case, we can now import the `deepchem` package to play with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PDiY03h35zF_",
        "outputId": "86a81a4d-5573-4b9f-b5d4-114fae630d48"
      },
      "source": [
        "import deepchem as dc\n",
        "dc.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.6.0.dev'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0u7qIZd5zGG"
      },
      "source": [
        "# Training a Model with DeepChem: A First Example\n",
        "\n",
        "Deep learning can be used to solve many sorts of problems, but the basic workflow is usually the same.  Here are the typical steps you follow.\n",
        "\n",
        "1. Select the data set you will train your model on (or create a new data set if there isn't an existing suitable one).\n",
        "2. Create the model.\n",
        "3. Train the model on the data.\n",
        "4. Evaluate the model on an independent test set to see how well it works.\n",
        "5. Use the model to make predictions about new data.\n",
        "\n",
        "With DeepChem, each of these steps can be as little as one or two lines of Python code.  In this tutorial we will walk through a basic example showing the complete workflow to solve a real world scientific problem.\n",
        "\n",
        "The problem we will solve is predicting the solubility of small molecules given their chemical formulas.  This is a very important property in drug development: if a proposed drug isn't soluble enough, you probably won't be able to get enough into the patient's bloodstream to have a therapeutic effect.  The first thing we need is a data set of measured solubilities for real molecules.  One of the core components of DeepChem is MoleculeNet, a diverse collection of chemical and molecular data sets.  For this tutorial, we can use the Delaney solubility data set. The property of solubility in this data set is reported in log(solubility) where solubility is measured in moles/liter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saTaOpXY5zGI"
      },
      "source": [
        "tasks, datasets, transformers = dc.molnet.load_delaney(featurizer='GraphConv')\n",
        "train_dataset, valid_dataset, test_dataset = datasets"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F922OPtL5zGM"
      },
      "source": [
        "I won't say too much about this code right now.  We will see many similar examples in later tutorials.  There are two details I do want to draw your attention to.  First, notice the `featurizer` argument passed to the `load_delaney()` function.  Molecules can be represented in many ways.  We therefore tell it which representation we want to use, or in more technical language, how to \"featurize\" the data.  Second, notice that we actually get three different data sets: a training set, a validation set, and a test set.  Each of these serves a different function in the standard deep learning workflow.\n",
        "\n",
        "Now that we have our data, the next step is to create a model.  We will use a particular kind of model called a \"graph convolutional network\", or \"graphconv\" for short."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEDcUsz35zGO"
      },
      "source": [
        "model = dc.models.GraphConvModel(n_tasks=1, mode='regression', dropout=0.2)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8UCFrrN5zGf"
      },
      "source": [
        "Here again I will not say much about the code.  Later tutorials will give lots more information about `GraphConvModel`, as well as other types of models provided by DeepChem.\n",
        "\n",
        "We now need to train the model on the data set.  We simply give it the data set and tell it how many epochs of training to perform (that is, how many complete passes through the data to make)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5K3rdGV5zGg",
        "outputId": "e2842e9a-81a0-4c75-c13f-9b51c12bf4f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(train_dataset, nb_epoch=100)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_14:0\", shape=(346,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_13:0\", shape=(346, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_17:0\", shape=(1004,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_16:0\", shape=(1004, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_20:0\", shape=(834,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_19:0\", shape=(834, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_23:0\", shape=(136,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_22:0\", shape=(136, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_11:0\", shape=(346,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_10:0\", shape=(346, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_13:0\", shape=(1004,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_12:0\", shape=(1004, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_15:0\", shape=(834,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_14:0\", shape=(834, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_17:0\", shape=(136,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_16:0\", shape=(136, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_19:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_18:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_21:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_20:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_23:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_22:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_25:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_24:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_27:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_26:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_8:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_29:0\", shape=(0,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_28:0\", shape=(0, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_9:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_14:0\", shape=(346,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_13:0\", shape=(346, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_17:0\", shape=(1004,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_16:0\", shape=(1004, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_20:0\", shape=(834,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_19:0\", shape=(834, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_23:0\", shape=(136,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_22:0\", shape=(136, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_14:0\", shape=(343,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_13:0\", shape=(343, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_17:0\", shape=(962,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_16:0\", shape=(962, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_20:0\", shape=(837,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_19:0\", shape=(837, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_23:0\", shape=(116,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_22:0\", shape=(116, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_11:0\", shape=(343,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_10:0\", shape=(343, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_13:0\", shape=(962,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_12:0\", shape=(962, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_15:0\", shape=(837,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_14:0\", shape=(837, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_17:0\", shape=(116,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_16:0\", shape=(116, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_14:0\", shape=(343,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_13:0\", shape=(343, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_17:0\", shape=(962,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_16:0\", shape=(962, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_20:0\", shape=(837,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_19:0\", shape=(837, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_23:0\", shape=(116,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_22:0\", shape=(116, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_13:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_16:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_19:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Reshape_22:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool_1/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_11:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_10:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_13:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_12:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_1:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_15:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_14:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_2:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Reshape_16:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_conv_1/Cast_3:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_14:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_13:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_4:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_17:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_16:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_20:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_19:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_6:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_23:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Reshape_22:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/private__graph_conv_keras_model/graph_pool/Cast_7:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.10741983413696289"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Zcd7jTd5zGr"
      },
      "source": [
        "If everything has gone well, we should now have a fully trained model!  But do we?  To find out, we must evaluate the model on the test set.  We do that by selecting an evaluation metric and calling `evaluate()` on the model.  For this example, let's use the Pearson correlation, also known as r<sup>2</sup>, as our metric.  We can evaluate it on both the training set and test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJc90fs_5zGs",
        "outputId": "d5e77721-9d13-46cc-b92d-ae650907d388"
      },
      "source": [
        "metric = dc.metrics.Metric(dc.metrics.pearson_r2_score)\n",
        "print(\"Training set score:\", model.evaluate(train_dataset, [metric], transformers))\n",
        "print(\"Test set score:\", model.evaluate(test_dataset, [metric], transformers))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set score: {'pearson_r2_score': 0.9230243721131834}\n",
            "Test set score: {'pearson_r2_score': 0.710351152392508}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQa88cbj5zGw"
      },
      "source": [
        "Notice that it has a higher score on the training set than the test set.  Models usually perform better on the particular data they were trained on than they do on similar but independent data.  This is called \"overfitting\", and it is the reason it is essential to evaluate your model on an independent test set.\n",
        "\n",
        "Our model still has quite respectable performance on the test set.  For comparison, a model that produced totally random outputs would have a correlation of 0, while one that made perfect predictions would have a correlation of 1.  Our model does quite well, so now we can use it to make predictions about other molecules we care about.\n",
        "\n",
        "Since this is just a tutorial and we don't have any other molecules we specifically want to predict, let's just use the first ten molecules from the test set.  For each one we print out the chemical structure (represented as a SMILES string) and the predicted log(solubility). To put these predictions in \n",
        "context, we print out the log(solubility) values from the test set as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSVqeYox5zGx",
        "outputId": "0a347bb4-6365-4936-f9ea-1ccc2f8b18a2"
      },
      "source": [
        "solubilities = model.predict_on_batch(test_dataset.X[:10])\n",
        "for molecule, solubility, test_solubility in zip(test_dataset.ids, solubilities, test_dataset.y):\n",
        "    print(solubility, test_solubility, molecule)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.4587058] [-1.60114461] c1cc2ccc3cccc4ccc(c1)c2c34\n",
            "[1.2067447] [0.20848251] Cc1cc(=O)[nH]c(=S)[nH]1\n",
            "[-0.74164057] [-0.01602738] Oc1ccc(cc1)C2(OC(=O)c3ccccc23)c4ccc(O)cc4 \n",
            "[-2.0942614] [-2.82191713] c1ccc2c(c1)cc3ccc4cccc5ccc2c3c45\n",
            "[-1.3151165] [-0.52891635] C1=Cc2cccc3cccc1c23\n",
            "[1.7279714] [1.10168349] CC1CO1\n",
            "[-0.08836162] [-0.88987406] CCN2c1ccccc1N(C)C(=S)c3cccnc23 \n",
            "[-1.0332144] [-0.52649706] CC12CCC3C(CCc4cc(O)ccc34)C2CCC1=O\n",
            "[-1.1491364] [-0.76358725] Cn2cc(c1ccccc1)c(=O)c(c2)c3cccc(c3)C(F)(F)F\n",
            "[0.11843605] [-0.64020358] ClC(Cl)(Cl)C(NC=O)N1C=CN(C=C1)C(NC=O)C(Cl)(Cl)Cl \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhZxVoVs5zMa"
      },
      "source": [
        "# Congratulations! Time to join the Community!\n",
        "\n",
        "Congratulations on completing this tutorial notebook! If you enjoyed working through the tutorial, and want to continue working with DeepChem, we encourage you to finish the rest of the tutorials in this series. You can also help the DeepChem community in the following ways:\n",
        "\n",
        "## Star DeepChem on [GitHub](https://github.com/deepchem/deepchem)\n",
        "This helps build awareness of the DeepChem project and the tools for open source drug discovery that we're trying to build.\n",
        "\n",
        "## Join the DeepChem Gitter\n",
        "The DeepChem [Gitter](https://gitter.im/deepchem/Lobby) hosts a number of scientists, developers, and enthusiasts interested in deep learning for the life sciences. Join the conversation!"
      ]
    }
  ]
}
